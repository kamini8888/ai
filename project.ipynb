{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1G7N7vSbUYJgu6VJO242LMWtE9boFvgnb",
      "authorship_tag": "ABX9TyO8KMD2lZPch1THbEWS57U0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamini8888/ai/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Flatten,Dense\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import matplotlib.pyplot as plot\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "rmGIaof7q1TL"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGESHAPE = [224, 224, 3]\n",
        "training_data = '/content/drive/MyDrive/kaggle/imagess/train'\n",
        "testing_data = '/content/drive/MyDrive/kaggle/imagess/test'"
      ],
      "metadata": {
        "id": "KHumQx-tq2Ue"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model = VGG16(input_shape=IMAGESHAPE, weights='imagenet', include_top=False)\n"
      ],
      "metadata": {
        "id": "0uVVfHGwrBpt"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each_layer in vgg_model.layers:\n",
        "\teach_layer.trainable = False\n"
      ],
      "metadata": {
        "id": "7Xauh7EtrEUc"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = glob('/content/drive/MyDrive/kaggle/imagess/train/*')\n"
      ],
      "metadata": {
        "id": "rdCBF0iNrIQB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_layer = Flatten()(vgg_model.output)\n",
        "prediction = Dense(len(classes), activation='softmax')(flatten_layer)\n"
      ],
      "metadata": {
        "id": "nMY4elwgrLac"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = Model(inputs=vgg_model.input, outputs=prediction)\n",
        "final_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P61OnXrirNrF",
        "outputId": "afc8a706-c95f-48ef-9d8e-f972fa0c55e5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 50178     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14764866 (56.32 MB)\n",
            "Trainable params: 50178 (196.01 KB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.compile(\n",
        "loss='categorical_crossentropy',\n",
        "optimizer='adam',\n",
        "metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "WZcEVDcurPoD"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "\t\t\t\t\t\t\t\tshear_range = 0.2,\n",
        "\t\t\t\t\t\t\t\tzoom_range = 0.2,\n",
        "\t\t\t\t\t\t\t\thorizontal_flip = True)\n",
        "testing_datagen = ImageDataGenerator(rescale =1. / 255)\n"
      ],
      "metadata": {
        "id": "vgB02981rSVl"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/kaggle/imagess/train',\n",
        "\t\t\t\t\t\t\t\t\t\t\t\ttarget_size = (224, 224),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tbatch_size = 4,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tclass_mode = 'categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjiYVrolrV00",
        "outputId": "ecf3e756-9746-4626-d497-0a06fbcec4a7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 481 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = testing_datagen.flow_from_directory('/content/drive/MyDrive/kaggle/imagess/test',\n",
        "\t\t\t\t\t\t\t\t\t\t\ttarget_size = (224, 224),\n",
        "\t\t\t\t\t\t\t\t\t\t\tbatch_size = 4,\n",
        "\t\t\t\t\t\t\t\t\t\t\tclass_mode = 'categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ljHGfOYryPM",
        "outputId": "c5bc20d6-7f95-475e-88e5-0248d9ec491a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 446 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fitted_model = final_model.fit_generator(\n",
        "training_set,\n",
        "validation_data=test_set,\n",
        "epochs=5,\n",
        "steps_per_epoch=len(training_set),\n",
        "validation_steps=len(test_set)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spWHRfEVsCTx",
        "outputId": "82616f5a-3874-4b45-fd9c-19353cfa1469"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-b2adf78dfb61>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  fitted_model = final_model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "121/121 [==============================] - 547s 4s/step - loss: 0.3203 - accuracy: 0.8857 - val_loss: 0.5162 - val_accuracy: 0.8161\n",
            "Epoch 2/5\n",
            "121/121 [==============================] - 527s 4s/step - loss: 0.1539 - accuracy: 0.9418 - val_loss: 0.5604 - val_accuracy: 0.8274\n",
            "Epoch 3/5\n",
            "121/121 [==============================] - 530s 4s/step - loss: 0.1137 - accuracy: 0.9584 - val_loss: 0.4007 - val_accuracy: 0.8722\n",
            "Epoch 4/5\n",
            "121/121 [==============================] - 541s 4s/step - loss: 0.1171 - accuracy: 0.9605 - val_loss: 0.6153 - val_accuracy: 0.8318\n",
            "Epoch 5/5\n",
            "121/121 [==============================] - 527s 4s/step - loss: 0.1471 - accuracy: 0.9480 - val_loss: 1.9257 - val_accuracy: 0.6547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.save('our_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18QIVC0q-NpS",
        "outputId": "73470a7f-997a-4a2e-a492-a3917084886a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the model\n",
        "model = load_model('our_model.h5')\n",
        "\n",
        "# Load and preprocess the image without using keras_preprocessing\n",
        "img_path = '/content/drive/MyDrive/kaggle/imagess/val/NORMAL/NORMAL2-IM-1427-0001.jpeg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "# Make predictions\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Print the result\n",
        "if prediction[0][0] > prediction[0][1]:\n",
        "    print('Person is safe.')\n",
        "else:\n",
        "    print('Person is affected with Pneumonia.')\n",
        "\n",
        "print(f'Predictions: {prediction}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UExTBOoB_hiB",
        "outputId": "bf6f1fd7-ad95-479d-a61e-33a540731217"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 643ms/step\n",
            "Person is safe.\n",
            "Predictions: [[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the model\n",
        "model = load_model('our_model.h5')\n",
        "\n",
        "# Load and preprocess the image without using keras_preprocessing\n",
        "img_path = '/content/drive/MyDrive/kaggle/chest_xray/train/PNEUMONIA/person1000_bacteria_2931.jpeg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_data = preprocess_input(img_array)\n",
        "\n",
        "# Make predictions\n",
        "prediction = model.predict(img_data)\n",
        "\n",
        "# Print the result\n",
        "if prediction[0][0] > prediction[0][1]:\n",
        "    print('Person is safe.')\n",
        "else:\n",
        "    print('Person is affected with Pneumonia.')\n",
        "\n",
        "print(f'Predictions: {prediction}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txvwU9IQ_nEC",
        "outputId": "691e89c9-7c60-4130-d009-a04c3d25aa2d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Person is affected with Pneumonia.\n",
            "Predictions: [[5.3103685e-25 1.0000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the model\n",
        "model = load_model('our_model.h5')\n",
        "\n",
        "# Load and preprocess the image without using keras_preprocessing\n",
        "img_path = '/content/drive/MyDrive/kaggle/imagess/val/NORMAL/NORMAL2-IM-1427-0001.jpeg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_data = preprocess_input(img_array)\n",
        "\n",
        "# Make predictions\n",
        "prediction = model.predict(img_data)\n",
        "\n",
        "# Print the result\n",
        "if prediction[0][0] > prediction[0][1]:\n",
        "    print('Person is safe.')\n",
        "else:\n",
        "    print('Person is affected with Pneumonia.')\n",
        "\n",
        "print(f'Predictions: {prediction}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I5HjIqvCMtC",
        "outputId": "807f0d7a-9948-405f-d755-60b8b5b339b2"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Person is safe.\n",
            "Predictions: [[1. 0.]]\n"
          ]
        }
      ]
    }
  ]
}